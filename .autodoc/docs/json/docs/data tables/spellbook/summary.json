{
  "folderName": "spellbook",
  "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook",
  "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook",
  "files": [
    {
      "fileName": "index.md",
      "filePath": "docs\\data tables\\spellbook\\index.md",
      "url": "https://dune.com/blob/master/data tables\\spellbook\\index.md",
      "summary": "The app technical guide covers the Spells feature of the Dune project. Spells are custom tables that are built and maintained by Dune and the community. The guide explains that Spells are available on Dune V2 and can be queried from both Spark SQL and Dune SQL V2 Query Engines. The guide also provides a link to the Spellbook GitHub repository where the Spells can be found. \n\nThe guide explains that the Spellbook is a retooling of the existing abstractions repository and a first-in-class open-source analytics engineering tool called dbt. Abstractions are some of the most queried tables on Dune, and the Spellbook aims to make the experience of creating them better. The guide explains that dbt allows for the writing and management of unit tests to spot and prevent any issues in the abstractions. \n\nThe guide also explains that there are two types of Spells: Sector Spells and Project Spells. Sector Spells are tables that take in data from multiple contracts and projects, standardize the data across them, and make it easy to query for this data and compare the metrics of different projects with each other. Project Spells allow projects to assemble their data into one neat table that has all the data they need in one place. \n\nThe guide provides information on how to contribute to the Spellbook and how to view available Spells. It also warns that the abstractions for V1 are no longer open for contributions and will be sunsetted with the V1 engine soon. \n\nOverall, the app technical guide provides a detailed explanation of the Spells feature of the Dune project, including how to use it, how to contribute to it, and how it can benefit users.",
      "questions": "1. What is the purpose of Spells in Dune and how are they maintained?\n- Spells are custom tables that cover a type of activity on the blockchain and are built and maintained by Dune and their community.\n\n2. What is the difference between Abstractions and Spells in Dune?\n- Abstractions are snippets of SQL executed on the data platform for the V1 engine, while Spells are models or tables that can be materialized into views and tables using dbt for the V2 engine.\n\n3. How can a blockchain SQL analyst contribute to Spellbook and what are some benefits of using dbt?\n- A blockchain SQL analyst can contribute to Spellbook by creating new Spells and submitting pull requests to the public GitHub repository. Using dbt allows for classical software engineering practices to be injected into writing SQL, including managing dependencies, writing and managing unit tests, and adding data integrity tests with minimal effort."
    }
  ],
  "folders": [
    {
      "folderName": "contributing",
      "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\contributing",
      "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\contributing",
      "files": [
        {
          "fileName": "index.md",
          "filePath": "docs\\data tables\\spellbook\\contributing\\index.md",
          "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\index.md",
          "summary": "The Spellbook technical guide is focused on providing information on how to cast a spell from scratch using the Spellbook app. The guide is divided into two main sections: Casting a Spell from Scratch and Video Guides. \n\nThe Casting a Spell from Scratch section provides a link to a guide on how to add a spell to the Spellbook app. This section is aimed at users who prefer to learn by doing and want to get started with the app. Additionally, the section provides a link to the Spellbook GitHub repository for users who want to take a look under the hood and understand the app's infrastructure.\n\nThe Video Guides section contains two video tutorials on how to use the Spellbook app. The first video is a DuneCon workshop by Megan Heintz, a Dune Team member, who walks users through Spellbook's infrastructure and how to migrate data to a spell. The second video tutorial is by Andrew Hong, who shows users the main protocol interactions and how to pull and transform data on Ethereum using the app. \n\nOverall, the Spellbook technical guide provides users with a comprehensive understanding of how to use the Spellbook app. The guide is aimed at users who want to learn by doing and those who want to understand the app's infrastructure. The video tutorials provide a step-by-step guide on how to use the app, making it easy for users to get started.",
          "questions": "1. What is the purpose of Spellbook and how does it relate to blockchain technology?\n   \n   The app technical guide does not provide clear information on the purpose of Spellbook or its relation to blockchain technology, so a blockchain SQL analyst might have to do further research or analysis to understand its relevance to their work.\n\n2. Are there any security considerations or vulnerabilities that need to be addressed when using Spellbook?\n\n   The app technical guide does not mention any security considerations or vulnerabilities related to Spellbook, so a blockchain SQL analyst might need to investigate further or consult with security experts to ensure the safety of their data.\n\n3. What programming languages or frameworks are used to develop Spellbook?\n\n   The app technical guide does not provide information on the programming languages or frameworks used to develop Spellbook, so a blockchain SQL analyst might need to examine the source code on GitHub or consult with the development team to understand the technical details of the app."
        }
      ],
      "folders": [
        {
          "folderName": "Adding A Spell",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\Adding A Spell",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\Adding A Spell",
          "files": [
            {
              "fileName": "1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
              "summary": "This app technical guide provides a step-by-step guide on how to set up Spellbook dbt on a local computer. The guide is divided into two main sections: prerequisites and setting up Spellbook dbt. The prerequisites section outlines the software and tools required to set up Spellbook dbt, including VSCode, Python 3.9, pip, pipenv, and git and GitHub. The section also provides links to resources for installing these tools and troubleshooting any issues that may arise.\n\nThe second section of the guide focuses on setting up Spellbook dbt. It provides instructions on how to clone the Spellbook repository, install the necessary packages, and initialize dbt. The guide also includes a sample configuration file with prompts that users can enter to configure dbt. The section concludes with instructions on how to create a new branch and push it to a remote GitHub repository.\n\nThe guide includes screenshots and a video tutorial to help users visualize the steps involved in setting up Spellbook dbt. The guide is intended for users who are new to Spellbook dbt and provides a comprehensive overview of the steps involved in setting up the tool. Overall, the guide is well-organized and easy to follow, making it an excellent resource for users who are new to Spellbook dbt.",
              "questions": "1. What is the purpose of Spellbook and how does it relate to blockchain technology?\n   - The app technical guide does not provide information on the purpose of Spellbook or its relation to blockchain technology.\n2. Are there any specific database management systems that Spellbook dbt is compatible with?\n   - The app technical guide mentions that during the setup process, users will be prompted to choose a database management system, with Databricks being one of the options.\n3. Are there any security considerations that need to be taken into account when setting up Spellbook?\n   - The app technical guide does not provide information on any security considerations that need to be taken into account when setting up Spellbook."
            },
            {
              "fileName": "2-decide-on-a-Spell-to-cast.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\2-decide-on-a-Spell-to-cast.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\2-decide-on-a-Spell-to-cast.md",
              "summary": "This app technical guide covers the process of deciding on a Spell to cast in the Dune app. The guide provides three ways to decide on a Spell, including having an idea of what abstract data is needed, looking at Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. The guide then provides an example of creating a migration Spell for translating the Keep3r network view_job_log abstraction from Dune's v1 database into a V2 Spell.\n\nThe guide also includes a note that Dune V1 Abstractions have been moved to a new repository, which needs to be cloned to access the code for migrating a V1 Abstraction to a Spell. The guide provides the full path to the view_job_log.sql file, which is needed to set up the file structure for the Spell's SQL schema and source files.\n\nOverall, this guide provides a step-by-step process for deciding on a Spell to cast and creating a migration Spell in the Dune app. It also includes helpful links and examples to guide users through the process.",
              "questions": "1. What is the purpose of the Dune Docs app and how does it relate to blockchain technology? \n   - The app technical guide does not provide information on the purpose of the Dune Docs app or its relation to blockchain technology.\n2. How does the migration Spell mentioned in the guide interact with blockchain data? \n   - The app technical guide does not provide information on how the migration Spell interacts with blockchain data.\n3. Are there any security considerations or best practices that should be followed when creating Spells in Dune? \n   - The app technical guide does not provide information on security considerations or best practices for creating Spells in Dune."
            },
            {
              "fileName": "3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
              "summary": "This technical guide provides instructions on how to set up the file structure for SQL, schema, and source files in the Dune Docs project. The guide explains that all Spells are stored in the `/spellbook/models` directory by project name and blockchain network. The folder names are all lowercase, and words are separated by underscores. The guide provides an example of the folder structure for the Keep3r network, where the folder is `/spellbook/models/keep3r_network/ethereum`. \n\nThe guide explains that if the project folder exists but a Spell is being created for a new blockchain, a folder for the new blockchain should be created. The guide then explains that three files need to be created: a `.sql` file for the Spell's logic, a `_schema.yml` file to define the Spell's purpose and add generic tests, descriptions, metadata, etc., and a `_sources.yml` file with any project-specific table dependencies. The guide provides an example of the file structure for a Spell folder. \n\nThe guide also explains the naming convention for Spell files. Schema files are named `[project_name]_[blockchain]_schema.yml`, sources files are named `[project_name]_[blockchain]_sources.yml`, and SQL files for Spells are named `[project_name]_[blockchain]_[spell_name].sql`. \n\nThe guide then provides an example of a specific v1 migration example where three additional `.sql` files are needed for a Spell called `keep3r_network_ethereum_view_job_log.sql`. The guide explains that these files are needed because the original `view_job_log.sql` V1 Abstraction has two `FROM` statements that reference two other files that are also abstractions that need to be converted into Spells. The guide also explains that a recursive check needs to be done to see if those abstractions depend on any other abstractions that have yet to be migrated to Spells. \n\nOverall, this technical guide provides a clear and detailed explanation of how to set up the file structure for Spells in the Dune Docs project. It provides examples and naming conventions for the different types of files needed for Spells and explains how to handle dependencies between Spells.",
              "questions": "1. What is the purpose of the app and how does it relate to blockchain technology?\n   Answer: The app technical guide is focused on setting up a file structure for SQL, schema, and source files for a project that involves blockchain networks. A blockchain SQL analyst might want to know more about the specific use case of the project and how it utilizes blockchain technology.\n\n2. What are the naming conventions for the files and folders in the app?\n   Answer: The app technical guide provides specific naming conventions for the files and folders used in the project. A blockchain SQL analyst might want to know more about these conventions to ensure consistency and organization in their work.\n\n3. How does the app handle dependencies between different files and abstractions?\n   Answer: The app technical guide explains how to identify and handle dependencies between different files and abstractions in the project. A blockchain SQL analyst might want to know more about this process to ensure that all necessary files and abstractions are properly migrated to Spells."
            },
            {
              "fileName": "4-identify-and-define-sources.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\4-identify-and-define-sources.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\4-identify-and-define-sources.md",
              "summary": "This app technical guide covers the process of identifying and defining sources in the Dune Docs project. The guide provides instructions on how to complete the `_sources.yml` file, which is used to specify the sources of data for the project. The file is formatted using YAML syntax, and it contains information about the version of the engine used, the name and description of the source, and the tables associated with the source.\n\nThe guide explains how to identify the sources that need to be named by searching for `FROM` statements in the V1 abstractions that are being migrated. The tables mentioned in these statements that are not abstractions are the ones that need to be included in the `_sources.yml` file. The guide provides an example of how to create a `keep3r_network_ethereum_sources.yml` file, which includes a description of the Keep3r Network, a marketplace for posting and accepting jobs to help run decentralized infrastructure. The file lists the tables associated with the source, such as `Keep3r_evt_LiquidityAddition` and `Keep3r_evt_KeeperWork`.\n\nOverall, this guide is essential for developers working on the Dune Docs project, as it provides clear instructions on how to identify and define sources of data. By following the steps outlined in the guide, developers can ensure that the project is properly structured and that the data is accurately represented.",
              "questions": "1. What is the purpose of the `_sources.yml` file in the Dune Docs project?\n    \n    The `_sources.yml` file in the Dune Docs project is used to identify and define sources for the project's data.\n\n2. How are the sources formatted in the `_sources.yml` file?\n    \n    The sources in the `_sources.yml` file are formatted with a name, a one-line description, and a list of tables.\n\n3. How can a blockchain SQL analyst determine which sources to name in the `_sources.yml` file?\n    \n    A blockchain SQL analyst can determine which sources to name in the `_sources.yml` file by searching for `FROM` statements in the V1 abstractions being migrated and looking for all tables mentioned that are not abstractions."
            },
            {
              "fileName": "6-write-your-spell-as-SELECT-statement.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\6-write-your-spell-as-SELECT-statement.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\6-write-your-spell-as-SELECT-statement.md",
              "summary": "This technical guide is focused on the app feature of the Dune Docs project. The guide provides a step-by-step process for writing a Spell as a SELECT statement. The guide starts by explaining that the endpoint is `_view_job_log.sql`, but the lowest-level dependency is `_view_job_migrations.sql`. The guide then explains that the process of migrating from V1 abstraction to V2 Spell starts by copying the contents of the V1 file to the `keep3r_network_ethereum_view_job_migrations.sql` file. The guide then explains how to modify the syntax from V1 abstraction style to V2 Spell style. \n\nThe guide also explains how to replace hard-coded references with JINJA templating. The guide clarifies that sources are data that have been added by the Dune team, while models are the `SELECT` statements defined in the `.sql` files stored inside the `spellbook/models` directory. The guide provides examples of how to format references to sources and models using JINJA templating. \n\nThe guide emphasizes the importance of testing each SQL file individually and fixing any errors before adding JINJA templating. The guide also provides tips on how to fix errors, including googling the error message or asking for help in the community Discord channel. \n\nOverall, this technical guide provides a detailed explanation of how to write a Spell as a SELECT statement and how to replace hard-coded references with JINJA templating. The guide is well-organized and easy to follow, making it a useful resource for developers working on the Dune Docs app.",
              "questions": "1. What is the purpose of the dune docs app?\n- The app technical guide does not provide information on the purpose of the dune docs app.\n\n2. What programming languages or technologies are used in this app?\n- The app technical guide mentions the use of SQL, PostgreSQL, Spark SQL, and JINJA templating.\n\n3. What is the process for migrating from V1 abstraction to V2 Spell style?\n- The app technical guide provides a detailed process for migrating from V1 abstraction to V2 Spell style, which involves modifying the syntax to Spark SQL, replacing hard-coded references with JINJA templating, and testing the SQL code in dune.com."
            },
            {
              "fileName": "7-configure-alias-and-materialization-strategy.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\7-configure-alias-and-materialization-strategy.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\7-configure-alias-and-materialization-strategy.md",
              "summary": "This technical guide covers the configuration of aliases and materialization strategies in the dune docs project. The guide explains how to configure aliases for Spells, which are SQL files that contain logic for data transformation, and how to specify the materialization strategy for each Spell. The guide also provides an overview of the four materialization strategies available in dbt, which are table, ephemeral, view, and incremental. \n\nThe `view` materialization strategy is the default in Spellbook, and it is used to store SQL logic without additional data. The `incremental` materialization strategy, on the other hand, allows dbt to insert or update records in a table according to the defined logic. The guide provides an example of how to create an incremental Spell by specifying the partition column, materialization type, and incremental strategy. \n\nTo configure aliases and materialization, the guide explains how to add configuration to the top of each SQL file. The configuration includes an alias for the Spell file that appears in the dune.com UI, as well as how the file is stored and categorized in the UI. The guide provides an example of how to configure aliases for a `view` materialization strategy. \n\nFinally, the guide explains how to add new models to the `dbt_project.yml` file in the Spellbook root folder. The models section specifies the project name, schema, and materialization strategy for the project as a whole, as well as the specific blockchain(s) that the Spells are created for. \n\nOverall, this guide provides a comprehensive overview of how to configure aliases and materialization strategies in the dune docs project. It is a useful resource for developers who are working on the app, API, data tables, or query features of the project.",
              "questions": "1. What are the available materialization strategies in dbt and which ones does Spellbook use?\n   \n   Answer: There are 4 materialization strategies in dbt: `table`, `ephemeral`, `view`, and `incremental`. Spellbook uses `view` and `incremental`.\n   \n2. How can an `incremental` Spell be created and what are the benefits of using it?\n\n   Answer: An `incremental` Spell can be created by including specific configuration statements in the Config section of the SQL file. The benefits of using it are faster run times, though the data won't be as fresh as `view` Spells.\n   \n3. How can aliases and materialization be configured for a Spell and where should this configuration be added?\n\n   Answer: Aliases and materialization can be configured for a Spell by adding configuration statements to the top of each SQL file. This configuration assumes a `view` materialization strategy. It should be added to the top of each SQL file."
            },
            {
              "fileName": "8-make-a-pull-request-get-merged-become-an-archwizard.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\8-make-a-pull-request-get-merged-become-an-archwizard.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\8-make-a-pull-request-get-merged-become-an-archwizard.md",
              "summary": "This section of the app technical guide covers the process of submitting a pull request to the official Spellbook in the Dune Docs project. The guide provides step-by-step instructions on how to commit local changes to a GitHub fork of the Spellbook and then submit a pull request. \n\nThe guide also includes a screenshot of the \"Open pull request\" button on the GitHub page and advises users to give their pull request an appropriate message. It also notes that comments from the team may be received and that improvements may need to be made before the pull request is approved. \n\nThe purpose of this guide is to help users contribute to the Spellbook and become Dune Archwizards. It is relevant to the app folder of the project as it pertains to the process of submitting changes to the app's codebase. \n\nAn example of how this guide could be useful is if a user has made changes to the Spellbook and wants to contribute those changes to the official version. By following the steps outlined in the guide, the user can ensure that their changes are properly submitted and reviewed by the team before being merged into the official Spellbook.",
              "questions": "1. What is the purpose of the Spellbook and how does it relate to blockchain technology?\n   \n   The app technical guide does not provide information on the purpose of the Spellbook or its relation to blockchain technology.\n\n2. Are there any specific coding languages or frameworks required to contribute to the Spellbook?\n\n   The app technical guide does not provide information on any specific coding languages or frameworks required to contribute to the Spellbook.\n\n3. Is there a review process for pull requests and who is responsible for reviewing them?\n\n   The app technical guide mentions that there is a review process for pull requests and that the Team provides comments for improvements, but it does not provide information on who is responsible for reviewing the pull requests."
            },
            {
              "fileName": "index.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\index.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\index.md",
              "summary": "This technical guide is titled \"How to Cast a Spell\" and is focused on the Spellbook feature of the Dune Docs project. The guide explains what Spellbook is, why it is used, and how to use it. Spellbook is an open-source dbt repository that allows users to create and maintain high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers. \n\nThe guide explains that blockchain data is packaged in blocks, which is one form of data we call \"Raw\" in Dune. Spellbook lets users create abstracted data sets, like dex.trades and nft.trades, which aggregate and organize raw data from multiple sources to make it much easier to query. The guide provides examples of how to use Spellbook to analyze blockchain data and how it can save time and effort.\n\nThe guide also provides an overview of the nft.trades Spell, which allows users to see industry-wide stats like total volume by # of txs and $USD, 24-hr volume, 24-hour and 7-day growth, market share by marketplace, volume by marketplace, and transaction count by marketplace. The guide explains how Spellbook can be used to make data more transparent, accessible, and meaningful together.\n\nThe guide provides 8 steps to casting a Spell, which includes doing some prerequisites and setting up Spellbook dbt, deciding on a Spell to cast, setting up the file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request, getting merged, and becoming an Archwizard. \n\nOverall, this technical guide provides a comprehensive overview of Spellbook and how to use it to analyze blockchain data. It is a useful resource for anyone looking to work with blockchain data and wants to learn how to use Spellbook to make the process easier and more efficient.",
              "questions": "1. What is Spellbook and how does it relate to blockchain data analytics?\n   \n   Spellbook is an open-source dbt repository that allows for the creation and maintenance of high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers, making it much easier to query and analyze blockchain data.\n\n2. How does the nft.trades Spell work and what insights can it provide for blockchain data analysts?\n   \n   The nft.trades Spell allows for the querying of industry-wide stats such as total volume by number of transactions and USD, 24-hour volume, 24-hour and 7-day growth, market share by marketplace, volume by marketplace, and transaction count by marketplace. It provides insights into the performance of NFT marketplaces and can be used to create dashboards and visualizations for analysis.\n\n3. What are the steps to casting a Spell and how can it benefit the web3 data community?\n   \n   The 8 steps to casting a Spell include prerequisites and setting up Spellbook dbt, deciding on a Spell to cast, setting up file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to become an Archwizard. Casting a Spell can benefit the web3 data community by allowing for the creation of standardized abstraction layers and making blockchain data more transparent, accessible, and meaningful for analysis."
            }
          ],
          "folders": [],
          "summary": "The \"Adding A Spell\" folder in the Dune Docs project is focused on guiding users through the process of creating and contributing a new Spell to the Spellbook feature. The Spellbook is an open-source dbt repository that allows users to create and maintain high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers.\n\nThe guide in this folder covers various aspects of creating a new Spell, including setting up prerequisites and the Spellbook dbt environment, deciding on a Spell to cast, setting up the file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to contribute the Spell to the official Spellbook.\n\nThis guide is particularly useful for developers and analysts who want to contribute to the Dune Docs project by creating new Spells or migrating existing V1 abstractions to V2 Spells. By following the steps outlined in the guide, users can ensure that their Spells are properly structured, tested, and submitted for review by the Dune Docs team.\n\nFor example, a user might want to create a new Spell that aggregates data from multiple sources to analyze the performance of a specific decentralized finance (DeFi) protocol. By following the guide, the user can set up the necessary environment, create the required files, write the SQL logic, and submit their Spell for review and potential inclusion in the official Spellbook.\n\nOverall, the \"Adding A Spell\" folder provides a comprehensive and detailed guide for users who want to contribute to the Dune Docs project by creating and submitting new Spells. The guide is well-organized and easy to follow, making it an excellent resource for users who are new to the Spellbook feature or the Dune Docs project as a whole.",
          "questions": ""
        },
        {
          "folderName": "examples",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\examples",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\examples",
          "files": [
            {
              "fileName": "daily-aggregation.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\daily-aggregation.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\daily-aggregation.md",
              "summary": "# Daily Aggregation\n\nThis technical guide covers the Daily Aggregation feature of the Dune Docs project. The Daily Aggregation feature sums all transfers for the day. The table is materialized as an incrementally loaded table updated every 15 minutes because the next step includes a slower `window` function to capture a rolling sum.\n\nThe guide explains the novel components that make this Spell incremental. The `<div data-gb-custom-block data-tag=\"if\"> </div>` JINJA block allows the addition of an arbitrary filter when running in “incremental” mode. Incremental mode is default, and a full refresh is denoted by a command-line argument to completely recreate the table. The block is used to filter for all data timestamped in the last two days. The model runs every fifteen minutes, but a look back of 2 days is allowed to account for data arriving late from the blockchain.\n\nThe guide also explains the use of “refs” in this spellset. A ref, like `{{ ref('tokens_ethereum_erc20') }}` is a reference to another model in the DBT project. The ref references the name of the file itself. That means, duplicate file names are not allowed.\n\nThe guide provides an example of the `transfers_ethereum_erc20_agg_day.sql` file, which contains the SQL code for the Daily Aggregation feature. The file uses the `config` function to set the alias, materialized, file format, incremental strategy, and unique key. The SQL code selects the blockchain, date truncated to the day, wallet address, token address, symbol, sum of the amount_raw, sum of the amount_raw divided by power(10, t.decimals), and unique_transfer_id. The file also uses the `left join` function to join the `transfers_ethereum_erc20` and `tokens_ethereum_erc20` tables. The `where` function is used to filter the data timestamped in the last two days. The `group by` function is used to group the data by date truncated to the day, wallet address, token address, t.symbol, and unique_tx_id.\n\nThe guide also provides an example of the `transfers_ethereum_schema.yml` file, which contains the schema for the Daily Aggregation feature. The file includes the name, meta, config, and columns of the table. The columns include blockchain, hour, wallet_address, token_address, symbol, amount_raw, amount, and amount_usd.\n\nIn summary, the Daily Aggregation feature of the Dune Docs project is an incrementally loaded table updated every 15 minutes that sums all transfers for the day. The feature uses a JINJA block to add an arbitrary filter when running in “incremental” mode and refs to reference another model in the DBT project. The `transfers_ethereum_erc20_agg_day.sql` file contains the SQL code for the feature, while the `transfers_ethereum_schema.yml` file contains the schema for the feature.",
              "questions": "1. What is the purpose of the \"incremental\" mode and how does it work?\n    \n    The \"incremental\" mode is used to update the table every 15 minutes with new data. It is the default mode and allows for a look back of 2 days to account for late data from the blockchain. A full refresh is denoted by a command line arg to completely recreate the table.\n    \n2. How does the app handle duplicates in the table and what is the unique key used for deduplication?\n    \n    The app uses a \"merge\" incremental strategy to handle duplicates in the table. The unique key used for deduplication is the `'unique_transfer_id'` which is created by coalescing several transfer features together.\n    \n3. What is a \"ref\" in this app and how is it used?\n    \n    A \"ref\" is a reference to another model in the DBT project. It references the name of the file itself and is used to avoid duplicate file names. In this app, it is used to reference the transfers and tokens models in the Ethereum ERC20 project."
            },
            {
              "fileName": "final-day-balance.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\final-day-balance.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\final-day-balance.md",
              "summary": "# Final Daily Balance\n\nThis technical guide is focused on the `app` folder of the Dune Docs project. The guide explains the final daily Ethereum ERC20 token balances spell. The spell is expanded to cover all days, not just the days with transfer activity. The guide also explains how price data is added, known rebase tokens are removed, and any tokens that resulted in large negative balances are removed.\n\nThe `balances_ethereum_erc20_day.sql` file contains the SQL code for the spell. The code uses the `transfers_ethereum_erc20_rolling_day` table to derive the `balances_ethereum_erc20_noncompliant` table. The `balances_ethereum_erc20_noncompliant` table looks for unique token addresses with larger negative balances, which indicate the contract may not be compliant with ERC20. The `tokens_ethereum_rebase` table is a static list of known rebase tokens that are managed.\n\nThe SQL code in `balances_ethereum_erc20_day.sql` calculates the daily token balances of ERC20 Ethereum tokens per wallet and contract address pair. The code uses the `prices` table to calculate the amount in USD. The code also removes rebase tokens from balances and likely non-compliant tokens due to negative balances.\n\nThe `transfers_ethereum_schema.yml` file contains the schema for the `balances_ethereum_erc20_day` table. The table has columns for the blockchain, day, wallet address, token address, amount raw, amount, amount USD, and symbol.\n\nOverall, this technical guide provides a detailed explanation of the final daily Ethereum ERC20 token balances spell and how it works. It also explains the tables used and how they are derived. The guide is useful for developers who want to understand how the spell works and how to use it in their projects.",
              "questions": "1. What is the purpose of the `transfers_ethereum_erc20_rolling_day` table and how is it used in the `balances_ethereum_erc20_day` query?\n   \n   The blockchain SQL analyst might want to know more about the `transfers_ethereum_erc20_rolling_day` table and how it is used in the `balances_ethereum_erc20_day` query to understand how daily token balances are calculated.\n\n2. How are rebase tokens identified and removed from the final daily Ethereum ERC20 token balances spell?\n   \n   The blockchain SQL analyst might want to know more about how rebase tokens are identified and removed from the final daily Ethereum ERC20 token balances spell to understand how the spell handles these types of tokens.\n\n3. What is the significance of the `balances_ethereum_erc20_noncompliant` table and how is it derived?\n   \n   The blockchain SQL analyst might want to know more about the `balances_ethereum_erc20_noncompliant` table and how it is derived to understand how the spell identifies non-compliant ERC20 tokens."
            },
            {
              "fileName": "index.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\index.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\index.md",
              "summary": "This app technical guide covers the Spellbook Examples for the Dune Docs project. The Spellbook Examples are a series of modular spells that demonstrate how to track daily balances for ERC-20 tokens that follow a contract standard set by the Ethereum Foundation. The guide begins by introducing ERC-20 tokens and the need to identify transfers to track daily balances. The main base Dune table used for this purpose is `erc20_ethereum.evt_Transfer`, which can be found via the data explorer.\n\nThe guide then goes on to describe the modular spells that make up the Spellbook Examples. The first spell is the Reformatted transfers spell, which reformats the data from the `evt_Transfer` table to make it easier to work with. The second spell is the Daily aggregation of transfers spell, which aggregates the transfers on a daily basis. The third spell is the Rolling sum of daily transfers spell, which calculates the rolling sum of daily transfers. The final spell is the Final daily balances for Ethereum ERC20 tokens spell, which calculates the final daily balances for the ERC-20 tokens.\n\nEach spell is described in detail, with examples and screenshots where appropriate. The guide is focused on the app folder of the project and provides a high-level overview of the purpose of each spell and how it applies to the app. Overall, this guide serves as a useful resource for developers looking to track daily balances for ERC-20 tokens using the Dune Docs app.",
              "questions": "1. What is the purpose of the Dune table `erc20_ethereum.evt_Transfer` and how does it relate to blockchain data analysis? \n   - The Dune table `erc20_ethereum.evt_Transfer` is used to track daily balances of ERC-20 tokens and is a key component in analyzing blockchain data related to token transfers.\n2. How does the Spellbook Examples module break down the analysis of ERC-20 tokens? \n   - The Spellbook Examples module breaks down the analysis of ERC-20 tokens into a series of modular spells, including reformatted transfers, daily aggregation, rolling sum, and final daily balances.\n3. Is this app technical guide specific to Ethereum or can it be applied to other blockchain platforms? \n   - The app technical guide specifically references ERC-20 tokens and the Ethereum Foundation, so a blockchain SQL analyst may wonder if the techniques and tools described can be applied to other blockchain platforms and token standards."
            },
            {
              "fileName": "reformatted.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\reformatted.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\reformatted.md",
              "summary": "The app technical guide is focused on the Reformatted Transfers feature of the Dune Docs project. The guide explains how the base table records the transfer amount to and from an account, and how it is munged into a union of sent transactions and received transactions to make it easier to sum up transfers. The guide also explains how WETH requires special handling, and how `zeroex_ethereum.weth9_evt_deposit` is added as a source to the model. \n\nThe guide further explains that the model is defined in a YAML file, where things like the description, tests, and metadata are defined. The guide also highlights that the JINJA config block defines that the alias for this view is `erc20`, and without this alias, the table name would default to the file name. The schema name for this view is defined in the `dbt_project.yml` file in the root of the Spellbook project. \n\nThe guide provides examples of the SQL code for the `transfers_ethereum_erc20` model, the YAML file for the model, and the `dbt_project.yml` file. The SQL code shows how the sent transfers, received transfers, deposited WETH, and withdrawn WETH are selected and unioned to create the `transfers_ethereum_erc20` model. The YAML file shows the metadata, description, and columns for the `transfers_ethereum_erc20` model. The `dbt_project.yml` file shows the schema and materialized view for the `transfers` and `ethereum` models. \n\nOverall, the app technical guide provides a detailed explanation of the Reformatted Transfers feature of the Dune Docs project, including how it works, how it is defined, and how it is implemented. The guide is useful for developers who want to understand how the feature works and how to use it in their own projects.",
              "questions": "1. What is the purpose of the `unique_tx_id` field in the SQL query?\n   \n   The `unique_tx_id` field is used to identify unique transactions and avoid duplicates in the table.\n\n2. How are contributors tracked in the YAML file?\n   \n   Contributors are tracked in the YAML file using the `contributors` field, where they can add their handle when writing or editing a spell.\n\n3. How is the schema name for this view defined in the project?\n   \n   The schema name for this view is defined in the `dbt_project.yml` file in the root of the Spellbook project, where schemas are defined by the directory structure."
            },
            {
              "fileName": "rolling-sum.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\rolling-sum.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\rolling-sum.md",
              "summary": "# Rolling Sum of Daily Transfers\n\nThis section of the app technical guide covers the rolling sum of daily transfers feature of the Dune Docs project. The purpose of this feature is to apply a rolling sum window function to each daily transfer sum. The query for this feature is provided in the `transfers_ethereum_erc20_rolling_day.sql` file. The query selects the blockchain, day, wallet address, token address, symbol, last updated timestamp, recency index, and the sum of the raw amount and amount of the ERC20 token held. \n\nThe `transfers_ethereum_schema.yml` file contains the schema for the `transfers_ethereum_erc20_rolling_hour` table. This table includes columns for the blockchain, hour, wallet address, token address, symbol, amount raw, amount, amount in USD, updated at timestamp, and recency index. \n\nThe purpose of these files is to provide the necessary code and schema for the rolling sum of daily transfers feature. The `transfers_ethereum_erc20_rolling_day.sql` file provides the query for the feature, while the `transfers_ethereum_schema.yml` file provides the schema for the table that stores the results of the query. \n\nOverall, this section of the app technical guide provides developers with the necessary information to implement the rolling sum of daily transfers feature in the Dune Docs project.",
              "questions": "1. What is the purpose of the Rolling Sum of Daily Transfers query in the context of blockchain SQL analysis?\n- The Rolling Sum of Daily Transfers query is used to apply a rolling sum window function to each daily transfer sum in order to calculate the amount of ERC20 tokens held by each wallet/contract pair.\n\n2. How does the Rolling Sum of Daily Transfers query handle missing data?\n- The Rolling Sum of Daily Transfers query fills in all the missing days and does a few more clean up steps in order to ensure accurate calculations.\n\n3. What information is included in the transfers_ethereum_erc20_rolling_hour schema?\n- The transfers_ethereum_erc20_rolling_hour schema includes information such as the blockchain, hour, wallet address, token address, ERC20 token symbol, rolling sum of raw amount of ERC20 token held, rolling sum of amount of ERC20 token held in USD, UTC timestamp when table was last updated, and recency index."
            }
          ],
          "folders": [],
          "summary": "This section of the app technical guide focuses on the Spellbook Examples for the Dune Docs project, specifically covering the daily aggregation of transfers, final daily balances, reformatted transfers, and rolling sum of daily transfers features. These modular spells demonstrate how to track daily balances for ERC-20 tokens that follow a contract standard set by the Ethereum Foundation. The guide is particularly useful for developers looking to track daily balances for ERC-20 tokens using the Dune Docs app.\n\nThe **Daily Aggregation** feature sums all transfers for the day and is incrementally loaded every 15 minutes. The guide explains the use of JINJA blocks and refs in this spellset, as well as providing examples of the `transfers_ethereum_erc20_agg_day.sql` file and the `transfers_ethereum_schema.yml` file.\n\nThe **Final Daily Balance** feature calculates the final daily Ethereum ERC20 token balances per wallet and contract address pair. The guide explains how price data is added, known rebase tokens are removed, and any tokens that resulted in large negative balances are removed. Examples of the `balances_ethereum_erc20_day.sql` file and the `transfers_ethereum_schema.yml` file are provided.\n\nThe **Reformatted Transfers** feature reformats the data from the `evt_Transfer` table to make it easier to work with. The guide explains how WETH requires special handling and how `zeroex_ethereum.weth9_evt_deposit` is added as a source to the model. Examples of the SQL code for the `transfers_ethereum_erc20` model, the YAML file for the model, and the `dbt_project.yml` file are provided.\n\nThe **Rolling Sum of Daily Transfers** feature applies a rolling sum window function to each daily transfer sum. The guide provides examples of the `transfers_ethereum_erc20_rolling_day.sql` file and the `transfers_ethereum_schema.yml` file.\n\nIn summary, this section of the app technical guide offers a comprehensive understanding of the Spellbook Examples for the Dune Docs project, focusing on the daily aggregation of transfers, final daily balances, reformatted transfers, and rolling sum of daily transfers features. The guide is beneficial for developers who want to implement these features in their own projects and gain a deeper understanding of how they work within the Dune Docs app.",
          "questions": ""
        }
      ],
      "summary": "The guide in the `Adding A Spell` folder is focused on guiding users through the process of creating and contributing a new Spell to the Spellbook feature within the Dune Docs project. The Spellbook is an open-source dbt repository that allows users to create and maintain high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers.\n\nThe guide covers various aspects of creating a new Spell, including setting up prerequisites and the Spellbook dbt environment, deciding on a Spell to cast, setting up the file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to contribute the Spell to the official Spellbook.\n\nThis guide is particularly useful for developers and analysts who want to contribute to the Dune Docs project by creating new Spells or migrating existing V1 abstractions to V2 Spells. By following the steps outlined in the guide, users can ensure that their Spells are properly structured, tested, and submitted for review by the Dune Docs team.\n\nFor example, a user might want to create a new Spell that aggregates data from multiple sources to analyze the performance of a specific decentralized finance (DeFi) protocol. By following the guide, the user can set up the necessary environment, create the required files, write the SQL logic, and submit their Spell for review and potential inclusion in the official Spellbook.\n\nOverall, the \"Adding A Spell\" folder provides a comprehensive and detailed guide for users who want to contribute to the Dune Docs project by creating and submitting new Spells. The guide is well-organized and easy to follow, making it an excellent resource for users who are new to the Spellbook feature or the Dune Docs project as a whole.",
      "questions": ""
    },
    {
      "folderName": "top tables",
      "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\top tables",
      "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\top tables",
      "files": [
        {
          "fileName": "dex.trades.md",
          "filePath": "docs\\data tables\\spellbook\\top tables\\dex.trades.md",
          "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\dex.trades.md",
          "summary": "# Dex.Trades App Technical Guide\n\nThis technical guide provides an overview of the dex.trades feature of the Dune Docs project. Dex.trades is a table that aggregates data across multiple decentralized exchange (DEX) platforms into one simple table. The purpose of this table is to standardize and normalize trading data across virtually all relevant DEXs, making it easier for users to query trading data for their favorite tokens without having to deal with all of the different DEX smart contracts themselves.\n\n## Column Data\n\nThe guide provides a detailed breakdown of the column data contained in the dex.trades table. The column names, data types, and descriptions are all listed in a table format. Some of the key columns include:\n\n- `block_time`: The timestamp of the block that included the transaction\n- `token_a_symbol` and `token_b_symbol`: The symbols of the two tokens that were traded\n- `token_a_amount` and `token_b_amount`: The amounts of token A and token B that were traded\n- `project`: The DEX on which the trade was executed\n- `usd_amount`: The USD value of the trade\n\n## Github Repo\n\nThe guide also provides a link to the public Github repo where the scripts that generate the dex.trades table can be found. The repo is located in the `ethereum/dex` folder of the Dune Analytics Spellbook.\n\nOverall, this technical guide provides a high-level overview of the dex.trades feature of the Dune Docs project, including its purpose, column data, and Github repo.",
          "questions": "1. What blockchains does dex.trades support?\n- The `blockchain` column in the table provides information on which blockchain the trade occurred on.\n\n2. Can dex.trades handle trades from all decentralized exchanges?\n- The app technical guide states that dex.trades standardizes and normalizes trading data across \"virtually all relevant decentralized exchanges,\" but it is unclear if there are any exchanges that are not supported.\n\n3. How is the USD value of a trade calculated?\n- The `usd_amount` column in the table provides the USD value of a trade, but it is unclear how this value is calculated."
        },
        {
          "fileName": "labels.md",
          "filePath": "docs\\data tables\\spellbook\\top tables\\labels.md",
          "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\labels.md",
          "summary": "The Labels technical guide is a documentation for the Address Labels feature on Dune. The guide explains what labels are, how to add them, and how to use them. Labels are metadata about an address, in the form of a key-value pair, where the key is the label type and the value is the label name. The Labels feature allows users to add, update, and query labels for any address. \n\nThe guide provides examples of what can be created with labels, such as labeling all addresses that used a certain dapp, all addresses that hold a certain amount of a token, or all addresses that use a dapp more than X times per month. Users can also come up with their own label types and names, as labels on Dune are open-ended and crowd-sourced. \n\nThe Labels table stores labels in the `labels.labels` table, which has a schema that includes columns such as `id`, `address`, `name`, `blockchain`, `author`, `source`, `updated_at`, `label_type`, and `model_name`. \n\nThe guide also provides a warning that the Using Labels section is currently under construction. \n\nOverall, the Labels technical guide provides a comprehensive explanation of the Address Labels feature on Dune, including what labels are, how to add them, and how to use them. It also provides examples of what can be done with labels and information on how labels are stored in the Labels table.",
          "questions": "1. What is the purpose of the labels.labels table and what data is stored in it?\n   \n   The labels.labels table stores metadata about labeled addresses, including the label name, type, author, source, and last update time, as well as the address and blockchain it describes. It also includes the label model name.\n\n2. How are labels added to addresses and what are some examples of labels that can be added?\n   \n   Labels can be added to addresses using Dune queries, which can be used to label addresses based on various criteria such as dapp usage, token holdings, and transaction history. Examples of labels that can be added include addresses that used a certain dapp, hold a certain amount of a token, or sent money to a specific address.\n\n3. Are there any limitations or delays when querying labels in SQL on dune.com?\n   \n   There might be a few minutes delay from adding the label on dune.com until it can be queried in SQL."
        },
        {
          "fileName": "nft.trades.md",
          "filePath": "docs\\data tables\\spellbook\\top tables\\nft.trades.md",
          "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\nft.trades.md",
          "summary": "The `nft.trades` technical guide provides an overview of the effort to make NFT trading data easily available to everyone on Dune. The guide explains that the table aggregates and standardizes data between different data platforms and provides auxiliary information and metadata all in one table. The guide also lists the platforms that have been indexed so far, including OpenSea, Rarible, SuperRare, CryptoPunks, Foundation, and LooksRare.\n\nThe guide explains how single item trades work, including the exchange of an item between a buyer and a seller, the identification of the item through a combination of `nft_contract_address` and `token_id`, and the metadata associated with the trade. The guide also explains how bundle trades and aggregator trades work and provides recommendations for working with these types of trades.\n\nThe guide includes examples of SQL queries that can be used to retrieve data from the `nft.trades` table, including all trades for a given NFT, trades in the last 24 hours on a given platform, and platform volumes in the last year. The guide also includes examples of dashboards that utilize parameters and look across the entire ecosystem.\n\nThe guide provides a detailed list of column data, including the data type and description of each column. The guide also explains that the SQL code that processes the data for every marketplace is open source and available in the Dune Analytics GitHub repository, allowing anyone to review the code, make pull requests, and submit code to add more marketplaces.\n\nOverall, the `nft.trades` technical guide provides a comprehensive overview of the effort to make NFT trading data easily available to everyone on Dune, including how the table works, how different types of trades work, examples of SQL queries and dashboards, and a detailed list of column data.",
          "questions": "1. What platforms are currently indexed by nft.trades?\n- OpenSea, Rarible, SuperRare, CryptoPunks, Foundation, and LooksRare are currently indexed by nft.trades.\n\n2. What metadata is provided about the traded NFT?\n- The metadata provided about the traded NFT includes nft_project_name and erc_standard.\n\n3. What should be done if a platform is not indexed by nft.trades?\n- If a platform is not indexed by nft.trades, the SQL code that processes the data for every marketplace is open source and available in their GitHub repository. Anyone can review the code, make pull requests, and submit code to add more marketplaces."
        },
        {
          "fileName": "prices.md",
          "filePath": "docs\\data tables\\spellbook\\top tables\\prices.md",
          "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\prices.md",
          "summary": "# Prices\n\nThis technical guide covers the `Prices` feature of the Dune Docs project. The `Prices` feature allows users to get the price of almost all relevant ERC20 tokens. The price data is pulled from the Coinpaprika API and is volume-weighted based on real-time market data, translated to USD.\n\nThe guide provides two tables for getting prices: `prices.usd` and `prices_from_dex_data`. The `prices.usd` table supports a range of ERC20 tokens. If the token you desire is not listed in this table, you can make a pull request to the GitHub repository or use the decentralized price feed `dex.view_token_prices` for V1 Engine.\n\nThe `prices_from_dex_data` table creates price feeds based on decentralized exchange trading data. This table covers much more assets than `prices.usd` since it covers all assets that are traded on any of the decentralized exchanges that are indexed in `dex.trades`. However, this table is very resource-intensive and can only be updated every few hours. The resolution is only hourly, so if you need minutely prices, you should refer to `prices.usd`.\n\nThe guide also explains how the `prices_from_dex_data` table works. The script generates median hourly prices based on data from decentralized exchanges found in `dex.trades`. It assigns asset prices based on a trading pair that has a price feed in `prices.usd`. For example, if the $SPELL/ETH pool is used, the script will dynamically calculate the price of $SPELL based on the price of $ETH that was exchanged for it.\n\nThe guide also highlights known issues with the `prices_from_dex_data` table. In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of this token do not have a price feed in `prices.usd`. In such cases, you have to manually construct a price feed.\n\nOverall, this technical guide provides a comprehensive explanation of the `Prices` feature of the Dune Docs project. It explains how to use the two tables provided to get prices and highlights known issues with the `prices_from_dex_data` table.",
          "questions": "1. What is the source of price data for this app?\n- The price data is pulled from the coinpaprika API.\n\n2. What is the difference between the `prices.usd` table and the table that creates price feeds based on decentralized exchange trading data?\n- The `prices.usd` table supports a range of erc20.tokens and has a resolution by minute, while the table that creates price feeds based on decentralized exchange trading data covers much more assets than `prices.usd` and has a resolution only by hour.\n\n3. What are the known issues with the script that generates median hourly prices based on data from decentralized exchanges found in `dex.trades`?\n- In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of a token do not have a price feed in `prices.usd`. In cases like this, a manual price feed must be constructed."
        },
        {
          "fileName": "tokens.md",
          "filePath": "docs\\data tables\\spellbook\\top tables\\tokens.md",
          "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\tokens.md",
          "summary": "The Tokens section of the app technical guide for the Dune Docs project covers token transfers and metadata. The guide is aimed at analysts who will be working with both fungible (erc20) and non-fungible (erc721 and erc1155) tokens. The guide provides information on several tables that are essential for working with tokens.\n\nThe Metadata tables section of the guide covers two tables: tokens.erc20 and tokens.nft. The tokens.erc20 table contains useful information such as the token symbol and the decimals for any given contract_address. The latter is needed to get the actual amount from raw amounts in on-chain data. The tokens.nft table contains the collection name and symbol for any given contract_address. These tables are usually joined on contract_address at the end of a query to make everything more human-readable.\n\nThe Transfer tables section of the guide covers two tables: erc20_ethereum.evt_Transfer and nft.transfers. The erc20_ethereum.evt_Transfer table contains all transfer events for every erc20 token. Analysts can find how to get erc20 balances, mints, and burns using a provided guide. The nft.transfers table contains all transfer events for every erc721 or erc1155 token. Analysts can learn how to leverage this to find nft balances, transfers, and mints in a provided guide.\n\nFinally, the guide provides a link to a guide on how to calculate native token balances like ethereum (ETH) balances. This guide is useful for analysts who need to calculate balances for native tokens.\n\nOverall, the Tokens section of the app technical guide provides essential information for analysts working with tokens. The guide covers metadata and transfer tables for both fungible and non-fungible tokens, as well as a guide on how to calculate native token balances.",
          "questions": "1. What types of tokens does this app support?\n   - The app supports both fungible (erc20) and nonfungible (erc721 and erc1155) tokens.\n2. What information can be found in the metadata tables?\n   - The metadata tables contain information such as the token symbol, decimals, collection name, and symbol for a given contract address.\n3. What transfer events can be found in the transfer tables?\n   - The transfer tables contain all transfer events for erc20, erc721, and erc1155 tokens, which can be used to find balances, transfers, mints, and burns."
        }
      ],
      "folders": [],
      "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\spellbook\\top tables` folder contains technical guides for various features of the Dune Docs project, specifically focusing on data tables and their usage. These guides are essential for analysts working with different aspects of the project, such as token transfers, metadata, prices, address labels, and NFT trades.\n\nFor example, the `dex.trades.md` guide provides an overview of the dex.trades feature, which aggregates data across multiple decentralized exchange (DEX) platforms into one simple table. This guide is useful for users who want to query trading data for their favorite tokens without dealing with different DEX smart contracts.\n\nThe `labels.md` guide covers the Address Labels feature on Dune, explaining what labels are, how to add them, and how to use them. This guide is helpful for users who want to label addresses based on specific criteria, such as usage of a certain dapp or holding a certain amount of a token.\n\nThe `nft.trades.md` guide provides a comprehensive overview of the effort to make NFT trading data easily available on Dune. This guide is useful for users who want to retrieve data from the `nft.trades` table, such as all trades for a given NFT or platform volumes in the last year.\n\nThe `prices.md` guide covers the `Prices` feature, which allows users to get the price of almost all relevant ERC20 tokens. This guide is helpful for users who want to use the `prices.usd` and `prices_from_dex_data` tables to get token prices and understand the limitations of each table.\n\nLastly, the `tokens.md` guide focuses on token transfers and metadata for both fungible (erc20) and non-fungible (erc721 and erc1155) tokens. This guide is essential for analysts working with tokens, as it covers metadata and transfer tables, as well as a guide on how to calculate native token balances.\n\nOverall, the guides in this folder provide valuable information for analysts working with various aspects of the Dune Docs project. They offer detailed explanations, examples, and insights into how these features fit into the larger project and how they can be used effectively.",
      "questions": ""
    }
  ],
  "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\spellbook` folder contains technical guides and resources for the Spells feature of the Dune project. Spells are custom tables that are built and maintained by Dune and the community, aiming to standardize and simplify data querying across multiple contracts and projects. The folder is divided into two subfolders: `contributing` and `top tables`.\n\nThe `contributing` subfolder provides a comprehensive guide on how to create and contribute a new Spell to the Spellbook. This guide is particularly useful for developers and analysts who want to contribute to the Dune Docs project by creating new Spells or migrating existing V1 abstractions to V2 Spells. For example, a user might want to create a new Spell that aggregates data from multiple sources to analyze the performance of a specific decentralized finance (DeFi) protocol. By following the guide, the user can set up the necessary environment, create the required files, write the SQL logic, and submit their Spell for review and potential inclusion in the official Spellbook.\n\nThe `top tables` subfolder contains technical guides for various features of the Dune Docs project, specifically focusing on data tables and their usage. These guides are essential for analysts working with different aspects of the project, such as token transfers, metadata, prices, address labels, and NFT trades. For instance, the `dex.trades.md` guide provides an overview of the dex.trades feature, which aggregates data across multiple decentralized exchange (DEX) platforms into one simple table. This guide is useful for users who want to query trading data for their favorite tokens without dealing with different DEX smart contracts.\n\nOverall, the guides in the `.autodoc\\docs\\json\\docs\\data tables\\spellbook` folder provide valuable information for analysts working with various aspects of the Dune Docs project. They offer detailed explanations, examples, and insights into how these features fit into the larger project and how they can be used effectively. By following these guides, users can ensure that their Spells are properly structured, tested, and submitted for review by the Dune Docs team, ultimately contributing to the standardization and simplification of data querying across the Dune ecosystem.",
  "questions": ""
}